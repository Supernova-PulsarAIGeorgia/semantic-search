{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"18QJoT2c8nYn6rBQnyfrd0W8ydKKqv7Um","authorship_tag":"ABX9TyMqACIBeEVbemf/zJ44yiXz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a6bdd5b7e4a64a93af517dae80a9e6ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_218ecb1c63714a45bdbf041a7567e9bd","IPY_MODEL_a7d05d3866414d24b65152a6d3f2095a","IPY_MODEL_a4fb4ab749d744779d1e24a0769a89d3"],"layout":"IPY_MODEL_ea79ca2e217943bbbecbea57b050c158"}},"218ecb1c63714a45bdbf041a7567e9bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c72c3bf835e404f97be23271e184a2c","placeholder":"​","style":"IPY_MODEL_612834c0d15346a59703177f98765ed3","value":""}},"a7d05d3866414d24b65152a6d3f2095a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3211ca52bdf84dad8566fec972b85f93","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ae722420c634d77bbb03cbb871b6a80","value":0}},"a4fb4ab749d744779d1e24a0769a89d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e500f5eb57d34db78e5490bed8156e27","placeholder":"​","style":"IPY_MODEL_b1a9c9596b2645ae80d666a69b2623c8","value":" 0/0 [00:00&lt;?, ?it/s]"}},"ea79ca2e217943bbbecbea57b050c158":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c72c3bf835e404f97be23271e184a2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"612834c0d15346a59703177f98765ed3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3211ca52bdf84dad8566fec972b85f93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7ae722420c634d77bbb03cbb871b6a80":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e500f5eb57d34db78e5490bed8156e27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1a9c9596b2645ae80d666a69b2623c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Semantic Similarity\n","\n","This notebook explores ways to compare two Georgian phrases. Given two short phrases, we want to calculate a metric that will measure the distance between them. This distance should be based on the likeliness of their meanings rather than the literal matching of their words.\n","\n","Then we use these comparison methods for semantic search. Given a corpus and a query sentence, we want to find the most similar sentences."],"metadata":{"id":"dVcSIZNZb_-m"}},{"cell_type":"code","source":["!pip install transformers sentence-transformers fasttext python-Levenshtein\n","\n","from sentence_transformers import SentenceTransformer, CrossEncoder, util\n","import Levenshtein as lev\n","from typing import List\n","import torch\n","import json"],"metadata":{"id":"6dI7-V1ygcxm","colab":{"base_uri":"https://localhost:8080/","height":748,"referenced_widgets":["a6bdd5b7e4a64a93af517dae80a9e6ce","218ecb1c63714a45bdbf041a7567e9bd","a7d05d3866414d24b65152a6d3f2095a","a4fb4ab749d744779d1e24a0769a89d3","ea79ca2e217943bbbecbea57b050c158","4c72c3bf835e404f97be23271e184a2c","612834c0d15346a59703177f98765ed3","3211ca52bdf84dad8566fec972b85f93","7ae722420c634d77bbb03cbb871b6a80","e500f5eb57d34db78e5490bed8156e27","b1a9c9596b2645ae80d666a69b2623c8"]},"executionInfo":{"status":"ok","timestamp":1665658839793,"user_tz":-240,"elapsed":10936,"user":{"displayName":"Salome Papiashvili","userId":"11513242675132952876"}},"outputId":"23465a8c-34f9-4c3f-d1f1-29bbff4a4881"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n","Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n","Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.7/dist-packages (0.20.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.7)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.13.1+cu113)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.97)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.7.3)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.12.1+cu113)\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.10.0)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n","Requirement already satisfied: Levenshtein==0.20.5 in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (0.20.5)\n","Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from Levenshtein==0.20.5->python-Levenshtein) (2.11.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.2.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n"]},{"output_type":"stream","name":"stderr","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"output_type":"stream","name":"stdout","text":["Moving 0 files to the new cache system\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6bdd5b7e4a64a93af517dae80a9e6ce"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Sentence-Transformers\n","\n","There are several multilingual models for semantic similarity available on [Sentence-Transformers](https://www.sbert.net/docs/pretrained_models.html). We used **paraphrase-multilingual-MiniLM-L12-v2**, a multilingual version of **paraphrase-MiniLM-L12-v2**, trained on parallel data for 50+ languages, and Georgian among them."],"metadata":{"id":"86JL9UklJBSU"}},{"cell_type":"code","source":["embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')"],"metadata":{"id":"IWW1XbiBgeE4","executionInfo":{"status":"ok","timestamp":1665658843122,"user_tz":-240,"elapsed":3340,"user":{"displayName":"Salome Papiashvili","userId":"11513242675132952876"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Loading a collection of Georgian proverbs as a sample text corpus and precalculating their embeddings with the above model."],"metadata":{"id":"ejqDbNQMgRpt"}},{"cell_type":"code","source":["corpus = json.load(open('./storage/texts.json'))\n","corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)"],"metadata":{"id":"ftKnn5AKebVi","executionInfo":{"status":"ok","timestamp":1665658855804,"user_tz":-240,"elapsed":12687,"user":{"displayName":"Salome Papiashvili","userId":"11513242675132952876"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def find_similar(corpus: List[str], \n","                 corpus_embedding: List[torch.Tensor], \n","                 queries: List[str], \n","                 embedder: SentenceTransformer, \n","                 top_k: int):\n","  assert len(corpus) == len(corpus_embeddings)\n","\n","  top_k = min(top_k, len(corpus))\n","  \n","  for query in queries:\n","    query_embedding = embedder.encode(query, convert_to_tensor=True)\n","\n","    # We use cosine-similarity and torch.topk to find the highest scores\n","    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n","    top_results = torch.topk(cos_scores, k=top_k)\n","\n","    print(\"\\n\\n======================\\n\\n\")\n","    print(\"Query:\", query)\n","    print(\"\\nTop 5 most similar sentences in corpus:\")\n","\n","    for score, idx in zip(top_results[0], top_results[1]):\n","      print(corpus[idx], \"(Score: {:.4f})\".format(score))\n"],"metadata":{"id":"HSNTsCBOiKmW","executionInfo":{"status":"ok","timestamp":1665658855804,"user_tz":-240,"elapsed":27,"user":{"displayName":"Salome Papiashvili","userId":"11513242675132952876"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Query sentences:\n","queries = [\n","    'ჯოჯოხეთი',\n","    'სიღარიბე',\n","    'სიკეთე', \n","    'ბოროტება',\n","    ]"],"metadata":{"id":"nUBPDkdVgkIo","executionInfo":{"status":"ok","timestamp":1665658855804,"user_tz":-240,"elapsed":25,"user":{"displayName":"Salome Papiashvili","userId":"11513242675132952876"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["find_similar(corpus, corpus_embeddings, queries, embedder, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Eh37DORl3_8","executionInfo":{"status":"ok","timestamp":1665658856542,"user_tz":-240,"elapsed":762,"user":{"displayName":"Salome Papiashvili","userId":"11513242675132952876"}},"outputId":"6059e6c0-b458-407d-da9f-c75cd0aac403"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","======================\n","\n","\n","Query: ჯოჯოხეთი\n","\n","Top 5 most similar sentences in corpus:\n","ჯოჯოხეთს ერთი მაშხალა აკლდაო (Score: 0.8702)\n","ქრთამი ჯოჯოხეთს ანათებსო (Score: 0.8582)\n","ჯოჯოხეთში ძახილია და გაგონება კი - არა (Score: 0.8146)\n","ჯოჯოხეთს ერთი მუგუზალი აკლდა და ისიც დაუმატესო (Score: 0.7652)\n","ცდა ბედის მონახევრეა (Score: 0.7096)\n","\n","\n","======================\n","\n","\n","Query: სიღარიბე\n","\n","Top 5 most similar sentences in corpus:\n","სიზარმაცე სიღარიბის გასაღებიაო (Score: 0.9292)\n","ობოლი გაზრდას მოელის, ღარიბი - გამდიდრებასო (Score: 0.7076)\n","ღარიბის ლუკმა ტკბილია (Score: 0.6758)\n","ღარიბ კაცს ხეირიანი შვილი რომ ყავდეს, ღარიბი აღარ იქნებაო. (Score: 0.6472)\n","საოხრეზე ნაშოვნი სატიალოზე დაიხარჯაო (Score: 0.5648)\n","\n","\n","======================\n","\n","\n","Query: სიკეთე\n","\n","Top 5 most similar sentences in corpus:\n","ყველაფერი დაიქცევა კეთილი საქმის მეტი (Score: 0.7723)\n","მადლი ჰქენი, მარილიც მოაყარეო (Score: 0.7573)\n","საშოვარი კარგია, ნაშოვარი ძვირფასი (Score: 0.7453)\n","კარგ მთქმელსა კარგი გამგონიც უნდა (Score: 0.7125)\n","ღარიბის ლუკმა ტკბილია (Score: 0.7122)\n","\n","\n","======================\n","\n","\n","Query: ბოროტება\n","\n","Top 5 most similar sentences in corpus:\n","ჯოჯოხეთს ერთი მაშხალა აკლდაო (Score: 0.7422)\n","პატარა ეშმაკმა დიდი ეშმაკი აცდინა (Score: 0.7012)\n","ქრთამი ჯოჯოხეთს ანათებსო (Score: 0.7003)\n","ყბედი ვინ მოღალა და მუნჯმაო (Score: 0.6971)\n","მტერი მოყვრულად მოსული, მტერზედაც უარესია (Score: 0.6939)\n"]}]},{"cell_type":"markdown","source":["# Cross-Encoder\n","\n","Instead of storing precomputed embeddings we can just concatenate sentences and let the model measure similarity at once. Such model is called [Cross Encoder](https://www.sbert.net/examples/training/cross-encoder/README.html?highlight=crossencoder)\n","\n","\n","![](https://raw.githubusercontent.com/UKPLab/sentence-transformers/master/docs/img/Bi_vs_Cross-Encoder.png)\n"],"metadata":{"id":"ghupLOBYPyWb"}},{"cell_type":"code","source":["model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n","# model = CrossEncoder('cross-encoder/stsb-roberta-base')"],"metadata":{"id":"2CotfbFZ17-4","executionInfo":{"status":"ok","timestamp":1665658857902,"user_tz":-240,"elapsed":1363,"user":{"displayName":"Salome Papiashvili","userId":"11513242675132952876"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def find_similar_ce(corpus: List[str],\n","                 queries: List[str], \n","                 model: CrossEncoder, \n","                 top_k: int):\n","\n","  top_k = min(top_k, len(corpus))\n","  \n","  for query in queries:\n","    pairs = [(query, sent) for sent in corpus]\n","    scores = model.predict(pairs)\n","    top_results = torch.topk(torch.Tensor(scores), k=top_k)\n","\n","    print(\"\\n\\n======================\\n\\n\")\n","    print(\"Query:\", query)\n","    print(\"\\nTop 5 most similar sentences in corpus:\")\n","\n","    for score, idx in zip(top_results[0], top_results[1]):\n","      print(corpus[idx], \"(Score: {:.4f})\".format(score))\n"],"metadata":{"id":"gPHBwEX70tyq","executionInfo":{"status":"ok","timestamp":1665658857902,"user_tz":-240,"elapsed":4,"user":{"displayName":"Salome Papiashvili","userId":"11513242675132952876"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["find_similar_ce(corpus, queries, model, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87-L-C4f0yoS","executionInfo":{"status":"ok","timestamp":1665658943524,"user_tz":-240,"elapsed":85625,"user":{"displayName":"Salome Papiashvili","userId":"11513242675132952876"}},"outputId":"512c7a96-a6ae-451b-b872-09b38e60a7fa"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","======================\n","\n","\n","Query: ჯოჯოხეთი\n","\n","Top 5 most similar sentences in corpus:\n","ძაღლი ხსენებაზედაო (Score: 8.1331)\n","ძალა ერთობაშია (Score: 8.1331)\n","გამშველებელს მოხვდებაო (Score: 8.1331)\n","ქვეითი ცხენოსანს დასცინოდა (Score: 8.1283)\n","კაცი კაცის წამალიაო (Score: 8.1283)\n","\n","\n","======================\n","\n","\n","Query: სიღარიბე\n","\n","Top 5 most similar sentences in corpus:\n","ძაღლი ხსენებაზედაო (Score: 8.1331)\n","ძალა ერთობაშია (Score: 8.1331)\n","გამშველებელს მოხვდებაო (Score: 8.1331)\n","ქვეითი ცხენოსანს დასცინოდა (Score: 8.1283)\n","კაცი კაცის წამალიაო (Score: 8.1283)\n","\n","\n","======================\n","\n","\n","Query: სიკეთე\n","\n","Top 5 most similar sentences in corpus:\n","აგრე არ უნდა, თაყაო, შენ რომ მამული გაჰყაო. (Score: 8.3258)\n","თუ თვალით ვერ დაინახო, ყურით გაგონილს ნუ დასდევო (Score: 8.3238)\n","ვერიდებოდი ღოლოსა, შემომხვდა ღობის ბოლოსა. (Score: 8.3156)\n","სიკვდილმა სთქვა: ერთი ისეთი ვერ მოვკალი, რომ სხვა რამეს არ დააბრალონო (Score: 8.2829)\n","ვიდრე ჭკვიანი დაფიქრდეს, გიჟი ხიდს გადაირბენსო (Score: 8.2536)\n","\n","\n","======================\n","\n","\n","Query: ბოროტება\n","\n","Top 5 most similar sentences in corpus:\n","აგრე არ უნდა, თაყაო, შენ რომ მამული გაჰყაო. (Score: 8.3899)\n","სიკვდილმა სთქვა: ერთი ისეთი ვერ მოვკალი, რომ სხვა რამეს არ დააბრალონო (Score: 8.3473)\n","თუ თვალით ვერ დაინახო, ყურით გაგონილს ნუ დასდევო (Score: 8.3430)\n","ვერიდებოდი ღოლოსა, შემომხვდა ღობის ბოლოსა. (Score: 8.2984)\n","გულკეთილობა კაცს ააშენებს, ბოროტება კი დააქცევს (Score: 8.2366)\n"]}]},{"cell_type":"markdown","source":["# Levenstein Distance\n","\n","Levenshtein distance is a metric for measuring the difference between two sequences. Distance between two words is the minimum number of single-character edits (insertions, deletions, or substitutions) required to get one word from the other.\n","\n","We can use this metric to measure phrase similarity. That would let us save space for storing models and embeddings, and coputation time."],"metadata":{"id":"Zu7noFAiPVkf"}},{"cell_type":"code","source":["def lev_dist(str1: str, str2: str) -> float:\n","        if not str1: return 0\n","        if not str2: return 0\n","        \n","        max_len = max(len(str1), len(str2))\n","        distance_norm = lev.distance(str1, str2) / max_len\n","\n","        return distance_norm\n","\n","'''\n","  Given document string and query finds minimal \n","  Levenstein Distance between fragments of document and query string.\n","'''\n","def min_lev_dist(doc, query):\n","  min_dist = float('inf')\n","  \n","  doc_words = doc.split(' ')\n","  query_words = query.split(' ')\n","\n","  doc_word_count = len(doc_words)\n","  query_word_count = len(query_words)\n","\n","  if doc_word_count <= query_word_count:\n","    return lev.distance(doc, query)\n","\n","  for i in range(doc_word_count - query_word_count+1):\n","    doc_fragment = ' '.join(doc_words[i:i+query_word_count])\n","    if len(doc_fragment) == 0: continue\n","\n","    cur_dist = lev_dist(doc_fragment, query)\n","    min_dist = min(min_dist, cur_dist)\n","  return min_dist\n","\n","\n","def find_similar_ld(corpus: List[str],\n","                    queries: List[str],\n","                    top_k: int):\n","\n","  top_k = min(top_k, len(corpus))\n","  \n","  for query in queries:\n","    scores = [-min_lev_dist(sent, query) for sent in corpus]\n","    top_results = torch.topk(torch.Tensor(scores), k=top_k)\n","\n","    print(\"\\n\\n======================\\n\\n\")\n","    print(\"Query:\", query)\n","    print(\"\\nTop 5 most similar sentences in corpus:\")\n","\n","    for score, idx in zip(top_results[0], top_results[1]):\n","      print(corpus[idx], \"(Score: {:.4f})\".format(score))"],"metadata":{"id":"F-ky_DkTh2VC","executionInfo":{"status":"ok","timestamp":1665658943525,"user_tz":-240,"elapsed":28,"user":{"displayName":"Salome Papiashvili","userId":"11513242675132952876"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["find_similar_ld(corpus, queries, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GNvT-MmU7iQu","executionInfo":{"status":"ok","timestamp":1665658943525,"user_tz":-240,"elapsed":26,"user":{"displayName":"Salome Papiashvili","userId":"11513242675132952876"}},"outputId":"fd8f451e-140b-45ac-83a2-27e4570c24fb"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","======================\n","\n","\n","Query: ჯოჯოხეთი\n","\n","Top 5 most similar sentences in corpus:\n","ცოდნა სამოთხეა და არცოდნა - ჯოჯოხეთი (Score: -0.0000)\n","ჯოჯოხეთში ძახილია და გაგონება კი - არა (Score: -0.1111)\n","ჯოჯოხეთს ერთი მაშხალა აკლდაო (Score: -0.1250)\n","ჯოჯოხეთს ერთი მუგუზალი აკლდა და ისიც დაუმატესო (Score: -0.1250)\n","ქრთამი ჯოჯოხეთს ანათებსო (Score: -0.1250)\n","\n","\n","======================\n","\n","\n","Query: სიღარიბე\n","\n","Top 5 most similar sentences in corpus:\n","სიზარმაცე სიღარიბის გასაღებიაო (Score: -0.2222)\n","მდიდარს უთხრეს: მშვიდობაშიო, ღარიბს უთხრეს – ვინ გაჩუქაო (Score: -0.3750)\n","ბავშვის პირით სიმართლე ღაღადებსო (Score: -0.3750)\n","სიხარბემ რა ნახა - ყველა დაჰკარგა (Score: -0.3750)\n","ობოლი გაზრდას მოელის, ღარიბი - გამდიდრებასო (Score: -0.3750)\n","\n","\n","======================\n","\n","\n","Query: სიკეთე\n","\n","Top 5 most similar sentences in corpus:\n","გაცემულ სიკეთეს ხალხი არ ივიწყებს (Score: -0.1429)\n","მეზობელო კარისაო, სინათლე ხარ თვალისაო (Score: -0.4286)\n","ისეთი გოდორი დასწანი, რომ შენ შვილისშვილებსაც გამოადგესო (Score: -0.5000)\n","ვეშაპი ისეთს არაფერს ჩაყლაპავს, მონელება არ შეეძლოს. (Score: -0.5000)\n","კაცს როცა არ უნდა, რიყეზე ისე გაივლის, ქვას არ დაინახავს (Score: -0.5000)\n","\n","\n","======================\n","\n","\n","Query: ბოროტება\n","\n","Top 5 most similar sentences in corpus:\n","გულკეთილობა კაცს ააშენებს, ბოროტება კი დააქცევს (Score: -0.0000)\n","ბერს ბერობა შეშვენის და ერს ერობა (Score: -0.3750)\n","წყალი რომ დაგუბდება, აყროლდება (Score: -0.4444)\n","კოკა წყალზე გატყდება, ქურდი ქურდობაში მოკვდება (Score: -0.5000)\n","ვეშაპი ისეთს არაფერს ჩაყლაპავს, მონელება არ შეეძლოს. (Score: -0.5000)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ek0KbpUY92C6","executionInfo":{"status":"ok","timestamp":1665658943525,"user_tz":-240,"elapsed":23,"user":{"displayName":"Salome Papiashvili","userId":"11513242675132952876"}}},"execution_count":11,"outputs":[]}]}